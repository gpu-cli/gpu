{
  "$schema": "https://gpu-cli.sh/schema/v1/gpu.json",
  // GPU CLI Configuration
  // InvokeAI - Professional Stable Diffusion web UI
  "project_id": "invokeai",
  "provider": "runpod",
  "outputs": ["invokeai/outputs/"],
  "encryption": false,
  // RTX 6000 Ada guarantees Python 3.11 (Ada Lovelace = CUDA 12.4)
  // InvokeAI 6.x requires Python 3.11+ (uses typing.Self)
  "gpu_type": "NVIDIA RTX 6000 Ada",
  "min_vram": 24,
  "workspace_size_gb": 60
  // Dependencies specified in pyproject.toml
  // Base image auto-selected based on GPU's CUDA tier
}
