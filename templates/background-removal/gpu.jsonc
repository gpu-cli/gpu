{
  "$schema": "https://gpu-cli.sh/schema/v1/gpu.json",
  // GPU CLI Configuration
  // InvokeAI with BiRefNet background removal node pre-installed
  "project_id": "background-removal",
  "provider": "runpod",
  "gpu_types": [
    { "type": "NVIDIA RTX 6000 Ada Generation" }
  ],
  "encryption": false,
  "min_vram": 24,
  "workspace_size_gb": 60,

  // Port forwarding for InvokeAI web UI
  "ports": [9090],

  // Startup launches setup + InvokeAI server
  "startup": "bash ./startup.sh",

  // Sync generated images back to local machine
  "outputs": ["invokeai/outputs/"],

  // Readiness hook - wait for InvokeAI API to be ready before marking service as ready
  // InvokeAI + BiRefNet model loading can take several minutes on first run
  "hooks": {
    "readiness": {
      "type": "command",
      "name": "invokeai-ready",
      "run": ["curl", "-sf", "http://localhost:9090/api/v1/app/version"],
      "retry_count": 120,
      "retry_delay_secs": 5,
      "timeout_secs": 10
    }
  },

  // Environment setup - runs during pod provisioning
  "environment": {
    "base_image": "runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04",

    "system": {
      "apt": [{ "name": "git" }]
    },
    "shell": {
      "steps": [
        // Install InvokeAI with xformers + BiRefNet dependencies
        // NOTE: Do NOT use -q flag - output keeps SSH connection alive during long installs
        {
          "run": "pip install 'invokeai[xformers]' timm kornia",
          "only_once": true,
          "timeout_sec": 600
        }
      ]
    }
  },

  // Keep pod alive for 60 min after idle (model loading takes time)
  "keep_alive_minutes": 60,

  "template": {
    "name": "Background Removal (InvokeAI + BiRefNet)",
    "description": "InvokeAI with BiRefNet background removal node pre-installed",
    "author": "gpu-cli"
  }
}
